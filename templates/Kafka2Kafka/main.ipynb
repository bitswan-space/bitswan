{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de0bf376",
   "metadata": {},
   "source": [
    "# Kafka to Kafka pipeline\n",
    "This pipeline receives events from Kafka, processes the events and returns them back to Kafka.\n",
    "\n",
    "The pipeline is triggered (started) when it receives an event from the relevant Kafka topic. \n",
    "\n",
    "The pipeline immediatelly processes the event, and then sends it to the sink topic.\n",
    "\n",
    "### Events\n",
    "It is recommended to transform events to JSON format as explained in section **Access and Work with received events** prior processing them.\n",
    "\n",
    "Once transformed, you can work with event as with standard Python dictionary.\n",
    "\n",
    "Example event transformed into the JSON format:\n",
    "```JSON\n",
    "{\n",
    "    'foo': 'bap'\n",
    "}\n",
    "```\n",
    "### Configuration\n",
    "Configuration is placed in `pipelines.conf` file in the pipeline folder.\n",
    "\n",
    "Example configuration:\n",
    "```\n",
    "# Specification of Kafka connection\n",
    "[connection:KafkaConnection]\n",
    "bootstrap_servers=<broker1>:9092,<broker2>:9092\n",
    "\n",
    "# Specification of source topic\n",
    "[pipeline:Kafka2KafkaPipeline:KafkaSource]\n",
    "topic=bs-kafka2kafka-source\n",
    "\n",
    "# Specification of sink topic, where processed data will be sent\n",
    "[pipeline:Kafka2KafkaPipeline:KafkaSink]\n",
    "topic=bs-kafka2kafka-sink\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0a1b93",
   "metadata": {},
   "source": [
    "## Import BitSwan \n",
    "Import BitSwan modules necessary for Kafka to Kafka pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4680223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bspump.jupyter import *\n",
    "import bspump.kafka\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad79b2",
   "metadata": {},
   "source": [
    "## Register connection to Kafka\n",
    "The connection details are specified in `pipelines.conf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee90d481-7bce-4c07-817f-f95980fdf922",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_connection\n",
    "def connection(app):\n",
    "  return bspump.kafka.KafkaConnection(app, \"KafkaConnection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50247b2",
   "metadata": {},
   "source": [
    "## Create test events\n",
    "In case you would like to test the pipeline with sample events prior running the pipeline, you can do so using calling `sample_events` method with your events as a parameter, as seen below. \n",
    "\n",
    "All the events which are put to `sample_events` are processes one after each other one.\n",
    "\n",
    "This step is not necessary to run the pipeline.\n",
    "\n",
    "```Python\n",
    "sample_events([\n",
    "    b\"\"\"{\"foo\":\"bap\"}\"\"\",\n",
    "    b\"\"\"{\"foo\":\"baz\"}\"\"\"\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional] Enter sample events here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5103360",
   "metadata": {},
   "source": [
    "## Define AutoPipeline\n",
    "Autopipeline specifies source, sink and name of the pipeline. These names are reffered to in configuration file `pipelines.conf`. See Autopipeline definition below, with code comments for better clarification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b06fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_pipeline(\n",
    "    # Specification of source topic, reffered to in config file section [pipeline:Kafka2KafkaPipeline:KafkaSource]\n",
    "    source=lambda app, pipeline: bspump.kafka.KafkaSource(app, pipeline, connection=\"KafkaConnection\"),\n",
    "    # Specification of sink topic, reffered to in config file section [pipeline:Kafka2KafkaPipeline:KafkaSink]\n",
    "    sink=lambda app, pipeline: bspump.kafka.KafkaSink(app, pipeline, connection=\"KafkaConnection\"),\n",
    "    # Name of the pipeline, reffered to in config file section [pipeline:Kafka2KafkaPipeline]\n",
    "    name=\"Kafka2KafkaPipeline\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fbadd6",
   "metadata": {},
   "source": [
    "## Access and work with received events \n",
    "When working with events from Kafka it is recommended to transform them to standard JSON format, which you can access as an dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e91027-d95c-41ec-9377-991ce5925c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foo': 'bap'}\n",
      "{'foo': 'baz'}\n"
     ]
    }
   ],
   "source": [
    "# Transform received event to JSON format\n",
    "event = json.loads(event.decode(\"utf8\"))\n",
    "event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21aa22f",
   "metadata": {},
   "source": [
    "### Modification of event content.\n",
    "You can access the content of the event by selecting the relevant key.\n",
    "Below, you can create multiple cells with code working with events.\n",
    "\n",
    "Example event modification:\n",
    "```Python\n",
    "event[\"foo\"] = event[\"foo\"].upper()\n",
    "event\n",
    "```\n",
    "\n",
    "Example output:\n",
    "```JSON\n",
    "{'foo': 'BAP'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dbe90b-9128-490d-8c09-33cf02caf240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dc85be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12bc244",
   "metadata": {},
   "source": [
    "## Tranform event to Kafka format before sending them out.\n",
    "Use `json.dumps(event).encode()` as below, to transform the event before sending them to Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6588afb-ce85-4b8c-bc58-cb2df0e7bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = json.dumps(event).encode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4a3256",
   "metadata": {},
   "source": [
    "## Send event to Kafka\n",
    "All events are sent to the Kafka sink topic specified in `pipelines.conf` at the end of pipeline **automatically**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
